{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68ae14b-e5cd-4d2c-9f9a-463c1f525701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache folder (C:\\Users\\Jainit\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\Jainit\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\Jainit\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n",
      "Cache folder (C:\\Users\\Jainit\\.cache\\selenium) cannot be created: Cannot create a file when that file already exists. (os error 183)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total job cards found: 71\n",
      "Scraped 50 jobs. Files saved as JSON and CSV.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Scroll down the page to load more job listings\n",
    "def scroll_page(driver, scroll_times=10, delay=2):\n",
    "    for _ in range(scroll_times):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "# Extract brief job description from individual job page\n",
    "def get_job_description(job_url, driver):\n",
    "    try:\n",
    "        driver.execute_script(\"window.open('');\")  # open new tab\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        driver.get(job_url)\n",
    "\n",
    "        # Wait until job description is loaded\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'show-more-less-html__markup')))\n",
    "        desc = driver.find_element(By.CLASS_NAME, 'show-more-less-html__markup').text.strip()\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        # Return first 300 characters for brevity\n",
    "        return desc[:300] + \"...\" if len(desc) > 300 else desc\n",
    "\n",
    "    except Exception as e:\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        return \"Description not available\"\n",
    "\n",
    "# Set up Chrome in headless mode (no GUI)\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Open LinkedIn job listings for Bhubaneswar\n",
    "driver.get(\"https://www.linkedin.com/jobs/search/?keywords=&location=Bhubaneswar\")\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'base-card')))\n",
    "scroll_page(driver, scroll_times=10, delay=2)\n",
    "\n",
    "# Find all job cards\n",
    "jobs = driver.find_elements(By.CLASS_NAME, 'base-card')\n",
    "print(f\"Total job cards found: {len(jobs)}\")\n",
    "\n",
    "jobs_data = []\n",
    "\n",
    "# Loop through each job listing (limit to 50)\n",
    "for idx, job in enumerate(jobs[:50]):\n",
    "    try:\n",
    "        # Scroll to the job element to ensure it loads\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", job)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Extract job details\n",
    "        title = job.find_element(By.CLASS_NAME, 'base-search-card__title').text.strip()\n",
    "        company = job.find_element(By.CLASS_NAME, 'base-search-card__subtitle').text.strip()\n",
    "        location = job.find_element(By.CLASS_NAME, 'job-search-card__location').text.strip()\n",
    "        link = job.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "\n",
    "        # Try to get posted date\n",
    "        try:\n",
    "            posted = job.find_element(By.CLASS_NAME, 'job-search-card__listdate').text.strip()\n",
    "        except:\n",
    "            posted = \"N/A\"\n",
    "\n",
    "        # Try to get company logo URL\n",
    "        try:\n",
    "            logo_url = job.find_element(By.CLASS_NAME, 'artdeco-entity-image').get_attribute('src')\n",
    "        except:\n",
    "            logo_url = \"N/A\"\n",
    "\n",
    "        # Get job description from individual job page\n",
    "        description = get_job_description(link, driver)\n",
    "\n",
    "        # Add the collected job data\n",
    "        jobs_data.append({\n",
    "            \"logo_url\": logo_url,\n",
    "            \"company\": company,\n",
    "            \"title\": title,\n",
    "            \"location\": location,\n",
    "            \"description\": description,\n",
    "            \"posted\": posted,\n",
    "            \"link\": link\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Job {idx+1}: Skipped due to error: {e}\")\n",
    "\n",
    "# Close browser after scraping\n",
    "driver.quit()\n",
    "\n",
    "# Save as JSON\n",
    "with open('jobs_bhubaneswar2.json', 'w') as f:\n",
    "    json.dump(jobs_data, f, indent=2)\n",
    "\n",
    "# Save as CSV\n",
    "pd.DataFrame(jobs_data).to_csv('jobs_bhubaneswar2.csv', index=False)\n",
    "\n",
    "print(f\"Scraped {len(jobs_data)} jobs. Files saved as JSON and CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1dda8-862c-4c0b-954f-7da2abbc7f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
